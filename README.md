![Project Logo](https://github.com/Gitstar-OC/Machine-Learning/Assets/Preview.png)

# Machine-Learning-Specialization ( In Progress...)

- This course is beginner friendly along with some tough challenges for intermidiate engineers in machines. Don't worry if you dont know python! Just give this a try üòÑüëç.

- This are my machine learning notes that I have created in my learning journey of AI and Machine with the help of some top instructor from [Deep Learning AI](https://www.deeplearning.ai/), This will surely help beginners and intermidiate people to learn and understand machine learning. Feel free to clone, and fork üç¥.

---
<!--
- #### I also have occasionally added questions like taught in classes  to help make sure you understand the content like this üôÇ
**Question:**
Description of question
- Option A
- Option B
>  <details><summary><b>Answer</b></summary> Solution will be given here, with some explaination in below lines</details>

---
-->

- `B` for Beginner, `I` for intermediate level, `A` for Advanced and `O` for optional

> `BN` for Easy Notebook, `IN` for Intermidiate, and `T` for Notebook Assignment to test what you have learned!!

## Start with the basics

- `B` [Overview of Machine Learning](Basics/Overview.md)
- `B` [Applications of Machine Learning](Basics/Applications.md)
- `B` [What is machine learning](Basics/MachineLearning.md)

### Difference between supervised and unsupervised machine learning

- `B` [Supervised Machine Learning Part 1](Supervised%20Learning/SupervisedLearning1.md)
- `B` [Supervised Machine Learning Part 2](Supervised%20Learning/SupervisedLearning2.md)
- `B` [Unsupervised Machine Learning Part 1](Unsupervised%20Machine%20Learning/UnsupervisedLearning1.md)
- `B` [Unsupervised Machine Learning Part 2](Unsupervised%20Machine%20Learning/UnsupervisedLearning2.md)

### Jupyter Notebooks

- Jupyter notebook is a type of `IDE` in machine learning which provides to many options to the developers to create and run the code. Check the below file to get started!

> **Note:** You should first clone the project and open it in your IDE or in jupyter notebook to understand it in depth.

### [Jupyter Notebook](Jupyter%20Notebooks/JupyterNotebook.md)

- `N` [JupyterNotebook](Jupyter%20Notebooks/IntroductiontoJupyterNotebook.ipynb) (**Clone and Open it in your IDE**)

---

## Superwised Machine Learning

- ### Regression Model

  - `B` [Linear Regression Part 1](Supervised%20Learning/Regression%20Model/LinearRegressionP1.md)
  - `B` [Linear Regression Part 2](Supervised%20Learning/Regression%20Model/LinearRegressionP2.md)
  - `BN` [Linear Regression Model Representation](Jupyter%20Notebooks/ModelRepresentation.ipynb) (**Open it in your IDE like VS Code or Jupyter Notebook**)
  - `B` [Cost Function Formula](Supervised%20Learning/Regression%20Model/CostFunctionFormula.md)
  - `B` [Cost Function Intuition](Supervised%20Learning/Regression%20Model/CostFunctionIntuition.md)
  - `B` [Visualizing the cost function](Supervised%20Learning/Regression%20Model/VisualizingCostFunction.md)
  - `B` [Visualization Examples](Supervised%20Learning/Regression%20Model/VisualizationExamples.md)
  - `BN` [Cost Function Model Representation](Jupyter%20Notebooks/CostFunctionVisualization.ipynb) (**Open it in your IDE and run the whole code by _Shift+Enter_**)

- ### Training Model with Gradient Descent

  - `B` [Gradient Descent](Supervised%20Learning/Gradient%20Descent/GradientDescent.md)
  - `B` [Implement Gradient Descent](Supervised%20Learning/Gradient%20Descent/ImplementGradientDescent.md)
  - `B` [Gradient Descent Intuition](Supervised%20Learning/Gradient%20Descent/GradientDescentIntuition.md)
  - `B` [Learning Rate](Supervised%20Learning/Gradient%20Descent/LearningRate.md)
  - `B` [Gradient Descent with Linear Regression](Supervised%20Learning/Gradient%20Descent/GradientDescentLinearRegression.md)
  - `B` [Running Gradient Descent](Supervised%20Learning/Gradient%20Descent/RunningGradientDescent.md)
  - `BN` [Gradient Descent Representation](Jupyter%20Notebooks/GradientDescentRepresentaion.ipynb) (**Open it in your IDE and run the whole code by _Shift+Enter_**)

- ###  Multiple Linear Regression

  - `B` [Multiple Features](Supervised%20Learning/Multiple%20Linear%20Regression/MultipleFeatures.md)
  - `B` [Vectorization Part 1](Supervised%20Learning/Multiple%20Linear%20Regression/VectorizationPart1.md)
  - `B` [Vectorization Part 2](Supervised%20Learning/Multiple%20Linear%20Regression/VectorizationPart2.md)
  - `BN` [Python, Numphy and Vectorization](Jupyter%20Notebooks/PythonNumpyAndVectorization.ipynb)  (**Open it in your IDE and run the whole code by _Shift+Enter_**)
  - `B` [Gradient Descent for Multiple Linear Regression](Supervised%20Learning/Multiple%20Linear%20Regression/GradientDescentforMultipleLinearRegression.md)
  - `BN` [Multiple Variable Linear Regression](Jupyter%20Notebooks/MultipleLinearRegression.ipynb)  (**Open it in your IDE and run the whole code by _Shift+Enter_**)

- ### Gradient Descent in Practice

  - `B` [Feature Scaling Part 1](Supervised%20Learning/Gradient%20Descent%20in%20Practice/FeatureScalingPart1.md)
  - `B` [Feature Scaling Part 2](Supervised%20Learning/Gradient%20Descent%20in%20Practice/FeatureScalingPart2.md)
  - `B` [Checking Gradient Descent for Convergence](Supervised%20Learning/Gradient%20Descent%20in%20Practice/CheckingGradientDescentforConvergence.md)
  - `B` [Choosing the Learning Rate](Supervised%20Learning/Gradient%20Descent%20in%20Practice/ChoosingtheLearningRate.md)
  - `BN` [Feature Scaling and Learning Rate](Jupyter%20Notebooks/FeatureScalingAndLearningRate.ipynb)  (**Open it in your IDE and run the whole code by _Shift+Enter_**)
  - `B` [Feature Engineering](Supervised%20Learning/Gradient%20Descent%20in%20Practice/FeatureEngineering.md)
  - `B` [Polynomial Regression](Supervised%20Learning/Gradient%20Descent%20in%20Practice/PolynomialRegression.md)
  - `BN` [Feature Engineering and Polynomial Regression](Jupyter%20Notebooks/FeatureEngineeringAndPolynomialRegression.ipynb)   (**Open it in your IDE and run the whole code by _Shift+Enter_**)
  - `BN` [Linear Regression with scikit-learn](Jupyter%20Notebooks/LRwithScikitLearn.ipynb)  (**Open it in your IDE and run the whole code by _Shift+Enter_**)
- `T` [Linear Regression Test Notebook/Lab](LinearRegressionTest.ipynb) (**Clone and Open it in your IDE, follow all the instructions given and write the solution code**)
- > Don't take any pressure of it, hints and solution are given in the notebook as well

- ### Classification with Logistic Regression

  - `B` [Classification](Supervised%20Learning/Classification%20with%20Logistic%20Regression/Motivations.md)
  - `BN` [Classification](Jupyter%20Notebooks/Classification.ipynb)  (**Open it in your IDE and run the whole code by _Shift+Enter_**)
  - `B` [Logistic Regression](Supervised%20Learning/Classification%20with%20Logistic%20Regression/LogisticRegression.md)
  - `BN` [Sigmoid Function and Logistic Regression](Jupyter%20Notebooks/SigmoidFunction.ipynb)  (**Open it in your IDE and run the whole code by _Shift+Enter_**)
  - `B` [Decision Boundary](Supervised%20Learning/Classification%20with%20Logistic%20Regression/DecisionBoundary.md)
  - `BN` [Decision Boundary](Jupyter%20Notebooks/DecisionBoundary.ipynb)  (**Open it in your IDE and run the whole code by _Shift+Enter_**)

- ### Cost Function for Logistic Regression

  - `B` [Cost Function for Logistic Regression](Supervised%20Learning/Cost%20Function%20for%20Logistic%20Regression/CostFunctionforLogisticRegression.md)
  - `BN` [Logistic Loss](Jupyter%20Notebooks/LogisticLoss.ipynb)
  - `B` [Simplified Cost Function for Logistic Regression](Supervised%20Learning/Cost%20Function%20for%20Logistic%20Regression/SimplifiedCostFunctionforLogisticRegression.md)
  - `IN` [Cost Function for Logistic Regression](Jupyter%20Notebooks/CostFunctionforLogisticRegression.ipynb)

- ### Gradient Descent for Logistic Regression

  - `B` [Gradient Descent Implementation](Supervised%20Learning/Gradient%20Descent%20for%20Logistic%20Regression/GradientDescentImplementation.md)
  - `IN` [Gradient Descent for Logistic Regression](Jupyter%20Notebooks/GradientDescentforLogisticRegression.ipynb)
  - `BN` [Logistic Regression with Scikit-Learn](Jupyter%20Notebooks/LogisticRegressionwithScikit-Learn.ipynb)

- ### The Problem of Overfitting

  - `B` [The Problem of Overfitting](Supervised%20Learning/The%20Problem%20of%20Overfitting/TheProblemofOverfitting.md)
  - `B` [Addressing Overfiting](Supervised%20Learning/The%20Problem%20of%20Overfitting/AddressingOverfiting.md)
  - `BN` [Overfitting](Jupyter%20Notebooks/Overfitting.ipynb)
  - `B` [Cost Function with Regularization](Supervised%20Learning/The%20Problem%20of%20Overfitting/CostFunctionwithRegularization.md)
  - `I` [Regularized Linear Regression](Supervised%20Learning/The%20Problem%20of%20Overfitting/RegularizedLinearRegression.md)
  - `I` [Regularized Logistic Regression](Supervised%20Learning/The%20Problem%20of%20Overfitting/RegularizedLogisticRegression.md)
  - `IN` [Regularization](Jupyter%20Notebooks/Regularization.ipynb)

- ### `T` [Logistic Regression Test](Jupyter%20Notebooks/LogisticRegressionTest.ipynb)

- > Don't take any pressure of it, hints and solution are given in the notebook as well

---

## Advanced Learning Algorithms

- [Advanced Learning Algorithms](Advanced%20Learning%20Algorithms/Welcome.md) (For => What you will learn in this part)

- ### Neural Network Intuition

  - `B` [Neurons and the Brain](Advanced%20Learning%20Algorithms/Neural%20Network%20Intuition/NeuronsAndBrain.md)
  - `I` [Demand Prediction](Advanced%20Learning%20Algorithms/Neural%20Network%20Intuition/DemandPrediction.md)
  - `B` [Recognizing Images](Advanced%20Learning%20Algorithms/Neural%20Network%20Intuition/RecognizingImages.md)

- ### Neural Network Model

  - `I` [Neural Network Layer](Advanced%20Learning%20Algorithms/Neural%20Network%20Model/NeuralNetworkLayer.md)
  - `A` [More Complex Neural Networks](Advanced%20Learning%20Algorithms/Neural%20Network%20Model/MoreComplexNeuralNetworks.md)
  - `A` [Inference: Making Predictions](Advanced%20Learning%20Algorithms/Neural%20Network%20Model/InferenceMakingPredictions.md)
  - `IN` [Neurons and Layers](Jupyter%20Notebooks/NeuronsAndLayers.ipynb) (**Open it in your IDE and run the whole code by _Shift+Enter_**)

- ### TensorFlow Implementation

  - `I` [Inference in Code](Advanced%20Learning%20Algorithms/TensorFlow%20Implementation/InferenceinCode.md)
  - `I` [Data in TensorFlow](Advanced%20Learning%20Algorithms/TensorFlow%20Implementation/DatainTensorFlow.md)
  - `I` [Building a Neural Network](Advanced%20Learning%20Algorithms/TensorFlow%20Implementation/BuildingaNeuralNetwork.md)
  - `AN` [Coffee Roasting in TensorFlow](Jupyter%20Notebooks/CoffeeRoastingTensorFlow.ipynb) (**Open it in your IDE and run the whole code by _Shift+Enter_**)

- ### Neural Network Implementation in Python

  - `I` [Forward prop in single layer](Advanced%20Learning%20Algorithms/Neural%20Network%20Implementation%20in%20Python/ForwardPropinSingleLayer.md)
  - `A` [General Implementation of Forward Propogation](Advanced%20Learning%20Algorithms/Neural%20Network%20Implementation%20in%20Python/GeneralImplementationofForwardPropagation.md)
  - `IN` [Coffee Roasting NumPy](Jupyter%20Notebooks/CoffeeRoastingNumpy.ipynb) (**Open it in your IDE and run the whole code by _Shift+Enter_**)

- Speculations on Artificial General Intelligence (AGI)
  - `B` [Is there a path to AGI?](Advanced%20Learning%20Algorithms/IsThereAPathToAGI.md)

- ### Vectorization (Optional)

  - `O` [How Neural Network are Implemented Effciently](Advanced%20Learning%20Algorithms/Vectorization/HowNeuralNetworksareImplementedEfficiently.md)
  - `O` [Matrix Multiplication](Advanced%20Learning%20Algorithms/Vectorization/MatrixMultiplication.md)
  - `O` [Matrix Multiplication Rules](Advanced%20Learning%20Algorithms/Vectorization/MatrixMultiplicationRules.md)
  - `O` [Matrix Multiplication Code](Advanced%20Learning%20Algorithms/Vectorization/MatrixMultiplicationCode.md)

- ### `T` [Neural Networks for Binary Classification Test](Jupyter%20Notebooks/NeuralNetworksforBinaryClassificationTest.ipynb)

- > Don't take any pressure of it, hints and solution are given in the notebook as well

> Note: The other files which are under development are commented, you can see the code in side it!

<!--

- ### Neural Network Training

  - [TensorFlow Implementation](Advanced%20Learning%20Algorithms/Neural%20Network%20Training/TensorFlowImplementation.md)
  - [Training Details](Advanced%20Learning%20Algorithms/Neural%20Network%20Training/TrainingDetails.md)

- ### Activation Functions

  - [Alternatives to the Sigmoid Activation](Advanced%20Learning%20Algorithms/Activation%20Functions/AlternativesTotheSigmoidActivation.md)
  - [Choosing Activation Functions](Advanced%20Learning%20Algorithms/Activation%20Functions/ChoosingActivationFunctions.md)
  - [Why do we need Activation Functions](Advanced%20Learning%20Algorithms/Activation%20Functions/WhydoWeNeedActivationFunctions.md)
  - `N` [ReLU Activation]()

- ### Multiclass Classification

  - [Multiclass](Advanced%20Learning%20Algorithms/Multiclass%20Classification/Multiclass.md)
  - [Softmax](Advanced%20Learning%20Algorithms/Multiclass%20Classification/Softmax.md)
  - [Neural Network with Softmax output](Advanced%20Learning%20Algorithms/Multiclass%20Classification/NeuralNetworkwithSoftmaxoutput.md)
  - [Improved Implementation of Softmax](Advanced%20Learning%20Algorithms/Multiclass%20Classification/ImprovedImplementationofSoftmax.md)
  - [Classification with Multiple Outputs](Advanced%20Learning%20Algorithms/Multiclass%20Classification/ClassificationwithMultipleOutputs.md) (Optional)
  - `N` [Softmax]()
  - `N` [Multiclass]()

- ### Additional Neural Network Concepts

  - [Advanced Optimization](Advanced%20Learning%20Algorithms/Additional%20Neural%20Network%20Concepts/AdvancedOptimization.md)
  - [Additional Layer Types](Advanced%20Learning%20Algorithms/Additional%20Neural%20Network%20Concepts/AdditionalLayerTypes.md)

- ### Back Propogation (Optional)

  - [What is a derivative?](Advanced%20Learning%20Algorithms/Back%20Propagation/)
  - [Computation Graph](Advanced%20Learning%20Algorithms/Back%20Propagation/ComputationGraph.md)
  - [Larger Neural Network Example](Advanced%20Learning%20Algorithms/Back%20Propagation/LargerNeuralNetworkExample.md)
  - `N` [Derivatives]()
  - `N` [Back Propogation]()

- ###  Advice for Applying Machine Learning

  - [Deciding What to try next](Advanced%20Learning%20Algorithms/Advice%20for%20Applying%20Machine%20Learning/DecidingWhattoTryNext.md)
  - [Evaluating a Model](Advanced%20Learning%20Algorithms/Advice%20for%20Applying%20Machine%20Learning/EvaluatingaModel.md)
  - [Model Selection and Training / Cross Validatiion / Test Sets](Advanced%20Learning%20Algorithms/Advice%20for%20Applying%20Machine%20Learning/ModelSelectionAndTrainingCVTS.md)
  - `N` [Model Evaluation and Selection]()

- ### Bias and Variance

  - [Diagnosing Bias and Variance](Advanced%20Learning%20Algorithms/Bias%20and%20Variance/DiagnosingBiasandVariance.md)
  - [Regularization and Bias/Variance](Advanced%20Learning%20Algorithms/Bias%20and%20Variance/RegularizationandBiasVariance.md)
  - [Establishing a baseline level of Performance](Advanced%20Learning%20Algorithms/Bias%20and%20Variance/EstablishingBaselineLevelofPerformance.md)
  - [Learning Curves](Advanced%20Learning%20Algorithms/Bias%20and%20Variance/LearningCurves.md)
  - [Deciding what to try next revisited](Advanced%20Learning%20Algorithms/Bias%20and%20Variance/DecidingWhattoTryNextRevisited.md)
  - [Bias / Variance and Neural Networks](Advanced%20Learning%20Algorithms/Bias%20and%20Variance/BiasVarianceandNeuralNetworks.md)
  - `N` [Diagnosing Bias and Variance]()

- ### Machine Learning Development Process

  - [Iterative Loop of ML Development](Advanced%20Learning%20Algorithms/Machine%20Learning%20Development%20Process/IterativeLoopofMLDevelopment.md)
  - [Error Analysis](Advanced%20Learning%20Algorithms/Machine%20Learning%20Development%20Process/ErrorAnalysis.md)
  - [Adding Data](Advanced%20Learning%20Algorithms/Machine%20Learning%20Development%20Process/AddingData.md)
  - [Transfer Learning: Using Data from a Different Task](Advanced%20Learning%20Algorithms/Machine%20Learning%20Development%20Process/TransferLearningUsingDatafromaDifferentTask.md)
  - [Full Cycle of Machine Learning Project](Advanced%20Learning%20Algorithms/Machine%20Learning%20Development%20Process/FullCycleofMachineLearningProject.md)
  - [Fairness, Bias, and Ethics](Advanced%20Learning%20Algorithms/Machine%20Learning%20Development%20Process/FairnessBiasandEthics.md)

- ### Skewed Datasets (Optional)

  - [Error Metrics for Skewed Datasets](Advanced%20Learning%20Algorithms/Skewed%20Datasets/ErrorMetricsforSkewedDatasets.md)
  - [Trading off precision and recall](Advanced%20Learning%20Algorithms/Skewed%20Datasets/TradingoffPrecisionandRecall.md)

- ### Decision Trees

  - [Decision Tree Model](Advanced%20Learning%20Algorithms/Decision%20Trees/DecisionTreeModel.md)
  - [Learning Process](Advanced%20Learning%20Algorithms/Decision%20Trees/LearningProcess.md)

- ### Decision Tree Learning

  - [Measuring Purity](Advanced%20Learning%20Algorithms/Decision%20Tree%20Learning/MeasuringPurity.md)
  - [Choosing a Split: Information Gain](Advanced%20Learning%20Algorithms/Decision%20Tree%20Learning/ChoosingaSplitInformationGain.md)
  - [Putting it Together](Advanced%20Learning%20Algorithms/Decision%20Tree%20Learning/PuttingitTogether.md)
  - [Using One-hot Encoding of Categorial Features](Advanced%20Learning%20Algorithms/Decision%20Tree%20Learning/UsingOneHotEncodingofCategoricalFeatures.md)
  - [Continuous Valued Features](Advanced%20Learning%20Algorithms/Decision%20Tree%20Learning/ContinuousValuedFeatures.md)
  - [Regression Trees](Advanced%20Learning%20Algorithms/Decision%20Tree%20Learning/RegressionTrees.md) (Optional)
  - `N` [Decision Trees]()

- ### Tree Ensembles

  - [Using Multiple Decison Trees](Advanced%20Learning%20Algorithms/Tree%20Ensembles/UsingMultipleDecisionTrees.md)
  - [Sampling with Replacement](Advanced%20Learning%20Algorithms/Tree%20Ensembles/SamplingwithReplacement.md)
  - [Random Forest Algorithm](Advanced%20Learning%20Algorithms/Tree%20Ensembles/RandomForestAlgorithm.md)
  - [XGBoost](Advanced%20Learning%20Algorithms/Tree%20Ensembles/XGBoost.md)
  - [When to Use Decision Trees](Advanced%20Learning%20Algorithms/Tree%20Ensembles/WhentoHaveDecisionTrees.md)
  - `N` [Tree Ensebles]()

---

## Unsupervised Machine Learning, Recommender Systems, Reinforcement Learning

- [Unsupervised Machine Learning](Unsupervised%20Learning/Welcome.md) (For => What you will learn in this part)

- ### Clustering

  - [What is Clustering](Unsupervised%20Learning/Clustering/WhatisClustering.md)
  - [K-means Intuition](Unsupervised%20Learning/Clustering/KmeansIntuition.md)
  - [K-means Algorithm](Unsupervised%20Learning/Clustering/KmeansAlgorithm.md)
  - [Optimization Objective](Unsupervised%20Learning/Clustering/OptimizationObjective.md)
  - [Initializing K-means](Unsupervised%20Learning/Clustering/InitializingKmeans.md)
  - [Choosing Numbers of clusters](Unsupervised%20Learning/Clustering/ChoosingNumbersofClusters.md)

- ### Anomaly Detection

  - [Finding Unusual Events](Unsupervised%20Learning/Anomaly%20Detection/FindingUnusualEvents.md)
  - [Gaussian (normal) distribution](Unsupervised%20Learning/Anomaly%20Detection/GaussianNormalDistribution.md)
  - [Anomoly Detection Algoritm](Unsupervised%20Learning/Anomaly%20Detection/AnomalyDetectionAlgorithm.md)
  - [Developing and Evaluating an Anomaly Detection System](Unsupervised%20Learning/Anomaly%20Detection/DevelopingandEvaluatingAnomalyDetectionSystem.md)
  - [Choosing What Features to Use](Unsupervised%20Learning/Anomaly%20Detection/ChoosingWhatFeaturestoUse.md)

- ### Collaborative Filtering

  - [Making Recommendations](Unsupervised%20Learning/Collaborative%20Filtering/MakingRecommendations.md)
  - [Using Per-Item Features](Unsupervised%20Learning/Collaborative%20Filtering/UsingPerItemFeatures.md)
  - [Collaborative Filtering Algorithm](Unsupervised%20Learning/Collaborative%20Filtering/CollaborativeFilteringAlgorithm.md)
  - [Binary Labels: Favs, Likes and clicks](Unsupervised%20Learning/Collaborative%20Filtering/BinaryLabelsFavsLikesandClicks.md)

- ### Recommender Systems Implementation Detail

  - [Mean Normalization](Unsupervised%20Learning/Recommender%20Systems%20Implementation/FindingRelatedItems.md)
  - [TensorFlow Implementation of Collaborative Filtering](Unsupervised%20Learning/Recommender%20Systems%20Implementation/TensorFlowImplementationofCollaborativeFiltering.md)
  - [Finding Relatd Items](Unsupervised%20Learning/Recommender%20Systems%20Implementation/FindingRelatedItems.md)

- ### Content - Based Filtering

  - [Collaborative Filtering vs Content-Based Filtering](Unsupervised%20Learning/Content-Based%20Filtering/CollaborativeFilteringvsContent-BasedFiltering.md)
  - [Deep Learning for Content-Based Filtering](Unsupervised%20Learning/Content-Based%20Filtering/DeepLearningforContent-BasedFiltering.md)
  - [Recommending from a Large Catalogue](Unsupervised%20Learning/Content-Based%20Filtering/RecommendingfromaLargeCatalogue.md)
  - [Ethical Use of Recommender Systems](Unsupervised%20Learning/Content-Based%20Filtering/EthicalUseofRecommenderSystems.md)
  - [TensorFlow Implementations fo Content-Based Filtering](Unsupervised%20Learning/Content-Based%20Filtering/TensorFlowImplementationsfoContent-BasedFiltering.md)

- ### Principal Componenet Analysis (Optional)

  - [Reducing Number of Features](Unsupervised%20Learning/Principal%20Component%20Analysis/ReducingNumberofFeatures.md)
  - [PCA algoritm](Unsupervised%20Learning/Principal%20Component%20Analysis/PCAAlgorithm.md)
  - [PCA in Code](Unsupervised%20Learning/Principal%20Component%20Analysis/PCAinCode.md)
  - `N` [PCA and Data Visualization]()

- ### Reinforcement Learning Introduction

  - [What is Reinforcement Learning?](Unsupervised%20Learning/Reinforcement%20Learning%20Introduction/WhatisReinforcementLearning.md)
  - [Mars Rover Example](Unsupervised%20Learning/Reinforcement%20Learning%20Introduction/MarsRoverExample.md)
  - [The Return in Reinforcement Learning](Unsupervised%20Learning/Reinforcement%20Learning%20Introduction/TheReturninReinforcementLearning.md)
  - [Making Decisions: Policies in Reinforcement Learning](Unsupervised%20Learning/Reinforcement%20Learning%20Introduction/MakingDecisionsPoliciesinReinforcementLearning.md)
  - [Review of Key Concepts](Unsupervised%20Learning/Reinforcement%20Learning%20Introduction/ReviewofKeyConcepts.md)

- ### State - Action Value Function

  - [State-action Value Function Definition](Unsupervised%20Learning/State-Action%20Value%20Function/StateActionValueFunctionDefinition.md)
  - [State-action Value Function Example](Unsupervised%20Learning/State-Action%20Value%20Function/StateActionValueFunctionExample.md)
  - `N` [State-action Value Function]()
  - [Bellman Equation](Unsupervised%20Learning/State-Action%20Value%20Function/BellmanEquation.md)
  - [Random (stochastic) Environment](Unsupervised%20Learning/State-Action%20Value%20Function/RandomEnvironment.md) (Optional)

- ### Continuous State Spaces

  - [Example of Continuous State Space Applications](Unsupervised%20Learning/Continuous%20State%20Spaces/exa)
  - [Lunar Lander](Unsupervised%20Learning/Continuous%20State%20Spaces/LunarLander.md)
  - [Learning the State-value Function](Unsupervised%20Learning/Continuous%20State%20Spaces/LearningtheStatevalueFunction.md)
  - [Algorithm Refinement: Improved Neural Network Architecture](Unsupervised%20Learning/Continuous%20State%20Spaces/AlgorithmRefinementImprovedNeuralNetworkArchitecture.md)
  - [Algorithm Refinement: E- Greedy Policy](Unsupervised%20Learning/Continuous%20State%20Spaces/AlgorithmRefinementEGreedyPolicy.md)
  - [Algorithm Refinement: Mini-Batch and Soft Updates](Unsupervised%20Learning/Continuous%20State%20Spaces/AlgorithmRefinementMiniBatchandSoftUpdates.md) (Optional)
  - [The State of Reinforcement Learning](Unsupervised%20Learning/Continuous%20State%20Spaces/TheStateofReinforcementLearning.md)

## Maths for Machine Learning

- ### Linear Algebra for Machine Learning and Data Science
  - `B` [Introduction to Numpy Arrays](Mathematics/IntroductionToNumpyArrays.ipynb)
  - `B` [Linear Systems as Matrices](Mathematics/LinearSystemsOnMatrices.ipynb)
  - `B` 

!! Most of the notes credit of this note goes to the **great man and teacher** _[Andrew Ng](https://en.wikipedia.org/wiki/Andrew_Ng)_ and his great education websites like _[Deep Learning AI](https://www.deeplearning.ai/)_ and _[Coursera](https://www.coursera.org/)_

  Welldone Champ
 # Give it a ‚≠ê if you liked this!
 <!--
-->
