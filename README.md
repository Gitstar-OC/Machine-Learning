# Machine-Learning-Specialization ( In Progress...)
- ### This course is beginner friendly along with some tough challenges for intermidiate engineers in machines. Don't worry if you dont know python! Just give this a try üòÑüëç. 
- ### This are my machine learning notes I have created in my learning journey of AI and Machine, This will surely help beginners and intermidiate people to learn and understand machine learning. Feel free to clone, and fork üç¥.

--- 
- #### I also have occasionally added questions like taught in classes  to help make sure you understand the content like this üôÇ
**Question:**
Description of question 
- Option A 
- Option B
>  Answer: Solution will be given here, with some explaination in below lines

---

>  `B` for Beginner, `I` for intermediate level and `A` for Advanced!!

>  `BN` for Easy Notebook, `IN` for Intermidiate, and `EN` for Notebook Assignment to test what you have learned!!


### Start with the basics
- `B` [Overview of Machine Learning](Basics/Overview.md) 
- `B` [Applications of Machine Learning](Basics/Applications.md)
- `B` [What is machine learning](Basics/MachineLearning.md)

### Difference between supervised and unsupervised machine learning
- `B` [Supervised Machine Learning Part 1](Supervised%20Learning/SupervisedLearning1.md)
- `B` [Supervised Machine Learning Part 2](Supervised%20Learning/SupervisedLearning2.md)
- `B` [Unsupervised Machine Learning Part 1](Unsupervised%20Learning/UnsupervisedLearning1.md)
- `B` [Unsupervised Machine Learning Part 2](Unsupervised%20Learning/UnsupervisedLearning2.md)

### Jupyter Notebooks
- Jupyter notebook is a type of `IDE` in machine learning which provides to many options to the developers to create and run the code. Check the below file to get started! 
> **Note:** You should first clone the project and open it in your IDE or in jupyter notebook to understand it in depth. 
### [Jupyter Notebook](Jupyter%20Notebooks/JupyterNotebook.md)

- `N` [JupyterNotebook](Jupyter%20Notebooks/IntroductiontoJupyterNotebook.ipynb) (**Clone and Open it in your IDE**)

--- 

## Superwised Machine Learning
- ### Regression Model
  - `B` [Linear Regression Part 1](Supervised%20Learning/Regression%20Model/LinearRegressionP1.md)
  - `B` [Linear Regression Part 2](Supervised%20Learning/Regression%20Model/LinearRegressionP2.md)
  - `BN` [Linear Regression Model Representation](Jupyter%20Notebooks/ModelRepresentation.ipynb) (**Open it in your IDE like VS Code or Jupyter Notebook**)
  - `B` [Cost Function Formula](Supervised%20Learning/Regression%20Model/CostFunctionFormula.md)
  - `B` [Cost Function Intuition](Supervised%20Learning/Regression%20Model/CostFunctionIntuition.md)
  - `B` [Visualizing the cost function](Supervised%20Learning/Regression%20Model/VisualizingCostFunction.md)
  - `B` [Visualization Examples](Supervised%20Learning/Regression%20Model/VisualizationExamples.md)
  - `IN` [Cost Function Model Representation](Jupyter%20Notebooks/CostFunctionVisualization.ipynb) (**Open it in your IDE and run the whole code by _Shift+Enter_**)

- ### Training Model with Gradient Descent 
  - `B` [Gradient Descent](Supervised%20Learning/Gradient%20Descent/GradientDescent.md)
  - `B` [Implement Gradient Descent](Supervised%20Learning/Gradient%20Descent/ImplementGradientDescent.md)
  - `B` [Gradient Descent Intuition ](Supervised%20Learning/Gradient%20Descent/GradientDescentIntuition.md)
  - `B` [Learning Rate](Supervised%20Learning/Gradient%20Descent/LearningRate.md)
  - `B` [Gradient Descent with Linear Regression ](Supervised%20Learning/Gradient%20Descent/GradientDescentLinearRegression.md)
  - `B` [Running Gradient Descent](Supervised%20Learning/Gradient%20Descent/RunningGradientDescent.md)
  - `IN` [Gradient Descent Representation](Jupyter%20Notebooks/GradientDescentRepresentaion.ipynb) (**Open it in your IDE and run the whole code by _Shift+Enter_**)

<!--
- ###  Multiple Linear Regression
  - [Multiple Features]()
  - [Vectorization Part 1]()
  - [Vectorization Part 2]()
  - `BN` [Python, Numphy and Vectorization]()
  - [Gradient Descent for Multiple Linear Regression]() 
  - `IN` [Multiple Linear Regression]() 

- ### Gradient Descent in Practice
  - [Feature Scaling Part 1]() 
  - [Feature Scaling Part 2]() 
  - [Checking Gradient Descent for Convergence]() 
  - [Choosing the Learning Rate]()
  - `N` [Feature Scaling and Learning Rate]() <!-- Add Level -->
  <!-- 
  - [Feature Engineering]()
  - [Polynomial Regression]() 
  - `N` [Feature Engineering and Polynomial Regression]() 
  - `N` [Linear Regression with scikit-learn]()
- `EN` [Linear Regression Assignment]() (**Open it in your IDE and write the solution for the test**)

- ### Classification with Logistic Regression
  - [Motivations]() 
  - `N` [Classification]()
  - [Logistic Regression]()
  - `N` [Sigmoid Function and Logistic Regression]() 
  - [Decision Boundary]() 
  - `N` [Decision Boundary]() 

- ### Cost Function for Logistic Regression 
  - [Cost Function for Logistic Regression]() 
  - `N` [Logistic Loss]() 
  - [Simplified Cost Function for Logistic Regression]() 
  - `N` [Cost Function for Logistic Regression]() 

- ### Gradient Descent for Logistic Regression 
  - [Gradient Descent Implementation]() 
  - `N` [Gradient Descent for Logistic Regression]() 
  - `N` [Logistic Regression with Scikit-Learn]() 

- ### The Problem of Overfitting 
  - [The Problem of Overfitting]() 
  - [Addressing Overfiting]() 
  - `N` [Overfitting]() 
  - [Cost Function with Regularization]() 
  - [Regularized Linear Regression]() 
  - [Regularized Logistic Regression]()
  - `N` [Regularization]()

## Advanced Learning Algotrithms
- [Advanced Learning Algorithms]() (For => What you will learn in this part)

- ### Neural Network Model
  - [Neural Network Layer]() 
  - [More Complex Neural Networks]() 
  - [Inference: Making Predictions]() 
  - `N` [Neurons and Layers]() 
  
- ### TensorFlow Implementation
  - [Inference in Code]() 
  - [Data in TensorFlow]() 
  - [Building a Neural Network]()
  - `N` [Coffee Roasting in TensorFlow]() 
  

- ### Neural Network Implementation in Python 
  - [Forward prop in single layer]() 
  - [General Implementation of Forward Propogation]() 
  - `N` [Coffee Roasting NumPy]()

- Speculations on Artificial General Intelligence (AGI)
  - [Is there a path to AGI?]() 

- ### Vectorization (Optional) 
  - [How Neural Network are Implemented Effciently]() 
  - [Matrix Multiplication]() 
  - [Matrix Multiplication Rules]() 
  - [Matrix Multiplication Code]() 

- ### Neural Network Training 
  - [TensorFlow Implementation]() 
  - [Training Details]() 

- ### Activation Functions 
  - [Alternatives to the Sigmoid Activation]() 
  - [Choosing Activation Functions]()
  - [Why do we need Activation Functions]() 
  - `N` [ReLU Activation]() 

- ### Multiclass Classification 
  - [Multiclass]() 
  - [Softmax]() 
  - [Neural Network with Softmax output]() 
  - [Improved Implementation of Softmax]() 
  - [Classification with Multiple Outputs]() (Optional)
  - `N` [Softmax]() 
  - `N` [Multiclass]() 

- ### Additional Neural Network Concepts
  - [Advanced Optimization]() 
  - [Additional Layer Types]() 

- ### Back Propogation (Optional) 
  - [What is a derivative?]() 
  - [Computation Graph]() 
  - [Larger Neural Network Example]() 
  - `N` [Derivatives]() 
  - `N` [Back Propogation]() 
  
- ###  Advice for Applying Machine Learning 
  - [Deciding What to try next]() 
  - [Evaluating a Model]() 
  - [Model Selection and Training / Cross Validatiion / Test Sets]() 
  - `N` [Model Evaluation and Selection]() 

- ### Bias and Variance 
  - [

- ### Machine Learning Development Process 
  - [

- ### Skewed Datasets (Optional) 
  - [


## Unsupervised Machine Learning
--> 



 <!--- Welldone Champ--->
 # Give it a ‚≠ê if you liked this!

