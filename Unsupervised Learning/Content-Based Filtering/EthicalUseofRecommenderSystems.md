Even though recommender systems have been very profitable for some businesses, that happens, some use cases that have left people and society at large worse off. However, you use recommender systems or for that matter other learning algorithms, I hope you only do things that make society at large and people better off. Let's take a look at some of the problematic use cases of recommender systems, as well as ameliorations to reduce harm or to increase the amount of good that they can do. As you've seen in the last few videos, there are many ways of configuring a recommender system. When we saw binary labels, the label y could be, does a user engage or did they click or did they explicitly like an item? When designing a recommender system, choices in setting the goal of the recommender system and a lot of choices and deciding what to recommend to users. For example, you can decide to recommend to users movies most likely to be rated five stars by that user. That seems fine. That seems like a fine way to show users movies that they would like. Or maybe you can recommend to the user products that they are most likely to purchase. That seems like a very reasonable use of a recommender system as well. Versions of recommender systems can also be used to decide what ads to show to a user. One thing you could do is to recommend or really to show to the user ads that are most likely to be clicked on. Actually, what many companies will do is try to show ads that are likely to be clicked on and where the advertiser had put in a high bid because for many ad models, the revenue that the company collects depends on whether the ad was clicked on and what the advertiser had bid per-click. While this is a profit-maximizing strategy, there are also some possible negative implications of this type of advertising. I'll give a specific example on the next slide. One other thing that many companies do is try to recommend products that generate the largest profit. If you go to a website and search for a product today, there are many websites that are not showing you the most relevant product or the product that you are most likely to purchase. But is instead trying to show you the products that will generate the largest profit for the company. If a certain product is more profitable for them, because they can buy it more cheaply and sell it at a higher price, that gets ranked higher in the recommendations. Now, many companies view a pressure to maximize profit. This doesn't seem like an unreasonable thing to do but on the flip side, from the user perspective, when a website recommends to you a product, sometimes it feels it could be nice if the website was transparent with you about the criteria by which it is deciding what to show you. Is it trying to maximize their profits or trying to show you things that are most useful to you? On video websites or social media websites, a recommender system can also be modified to try to show you the content that leads to the maximum watch time. Specifically, websites that are an ad revenue tend to have an incentive to keep you on the website for a long time. Trying to maximize the time you spend on the site is one way for the site to try to get more of your time so they can show you more ads. Recommender systems today are used to try to maximize user engagement or to maximize the amount of time that someone spends on a site or a specific app. Whereas the first two of these seem quite innocuous, the third, fourth, and fifth, they may be just fine. They may not cause any harm at all. Or they could also be problematic use cases for recommender systems. Let's take a deeper look at some of these potentially problematic use cases. Let me start with the advertising example. It turns out that the advertising industry can sometimes be an amplifier of some of the most harmful businesses. They can also be an amplifier of some of the best and the most fruitful businesses. Let me illustrate with a good example and a bad example. Take the travel industry. I think in the travel industry, the way to succeed is to try to give good travel experiences to users, to really try to serve users. Now it turns out that if there's a really good travel company, they can sell you a trip to fantastic destinations and make sure you and your friends and family have a lot of fun. Then a good travel business, I think will often end up being more profitable. The other business is more profitable. They can then bid higher for ads. It can afford to pay more to get users. Because it can afford to bid higher for ads an online advertising site will show its ads more often and drive more users to this good company. This is a virtuous cycle where the more users you serve well, the more profitable the business, and the more you can bid more for ads and the more traffic you get and so on. Just virtuous circle will maybe even tend to help the good travel companies do even better statistically example. Let's look at the problematic example. The payday loan industry tends to charge extremely high-interest rates, often to low-income individuals. One of the ways to do well in the payday loan business is to be really efficient as squeezing customers for every single dollar you can get out of them. If there's a payday loan company that is very good at exploiting customers, really squeezing customers for every single dollar, then that company will be more profitable. Thus they can be higher for ads. Because they can get bid higher for ads they will get more traffic sent to them. This allows them to squeeze even more customers and explore even more people for profit. This in turn, also increase a positive feedback loop. Also, a positive feedback loop that can cause the most exploitative, the most harmful payday loan companies to get sent more traffic. This seems like the opposite effect than what we think would be good for society. I don't know that there's an easy solution to this. These are very difficult problems that recommender systems face. One amelioration might be to refuse to set ads from exploitative businesses. Of course, that's easy to say. But how do you define what is an exploitative business and what is not, is a very difficult question. But as we build recommender systems for advertising or for other things, I think these are questions that each one of us working on these technologies should ask ourselves so that we can hopefully invite open discussion and debate, get multiple opinions from multiple people, and try to come up with design choices that allows our systems to try to do much more good than potential harm. Let's look at some other examples. It's been widely reported in the news that maximizing user engagement such as the amount of time that someone watches videos on a website or the amount of time someone spends on social media. This has led to large social media and video sharing sites to amplify conspiracy theories or hate and toxicity because conspiracy theories and certain types of hate toxic content is highly engaging and causes people to spend a lot of time on it. Even if the effect of amplifying conspiracy theories amplify hidden toxicity turns out to be harmful to individuals and to society at large. One amelioration for this partial and imperfect is to try to filter out problematic contents such as hate speech, fraud, scams, maybe certain types the violent content. Again, the definitions of what exactly we should filter out is surprisingly tricky to develop. And this is a set of problems that I think companies and individuals and even governments have to continue to wrestle with. Just one last example. When a user goes to many apps or websites, I think users think the app or website I tried to recommend to the user thinks that they will like. I think many users don't realize that many apps and websites are trying to maximize their profit rather than necessarily the user's enjoyment of the media items that are being recommended. I would encourage you and other companies if at all possible, to be transparent with users about a criteria by which you're deciding what to recommend to them. I know this isn't always easy, but ultimately, I hope that being more transparent with users about why we're showing them and why will increase trust and also cause our systems to do more good for society. Recommender systems are very powerful technology, a very profitable, a very lucrative technology. There are also some problematic use cases. If you are building one of these systems using recommender technology or really any other machine learning or other technology. I hope you think through not just the benefits you can create, but also the possible harm and invite diverse perspectives and discuss and debate. Please only build things and do things that you really believe can be society better off. I hope that collectively, all of us in AI can only do work that makes people better off. Thanks for listening. We have just one more video to go in recommender systems in which we take a look at some practical tips for how to implement a content-based filtering algorithm in TensorFlow. Let's go on to that last video on recommender systems.